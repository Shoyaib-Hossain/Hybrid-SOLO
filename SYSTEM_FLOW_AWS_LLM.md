# Updated System Flow - Hybrid Threat Detection with AWS Cloud LLM

**Date:** October 22, 2025  
**Configuration:** AWS EC2 Remote LLM (CodeLlama 13B)

---

## ğŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Browser  â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  Web Application â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  Threat Detector    â”‚
â”‚  localhost:3000 â”‚         â”‚   (Flask)        â”‚         â”‚    (Flask API)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  Port: 3000      â”‚         â”‚   Port: 8081        â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                     â”‚
                                                                     â”‚ HTTP
                                                                     â–¼
                                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                          â”‚   AWS EC2 Instance  â”‚
                                                          â”‚  98.92.213.6:11434  â”‚
                                                          â”‚                     â”‚
                                                          â”‚  Ollama Server      â”‚
                                                          â”‚  CodeLlama 13B      â”‚
                                                          â”‚  (19GB Model)       â”‚
                                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Detailed Request Flow

### **Step 1: User Login Attempt**
```
User submits login form
  â†“
POST http://localhost:3000/login
  â”œâ”€ username: "admin' OR '1'='1"
  â””â”€ password: "test123"
```

### **Step 2: Web Application Processing**
**File:** `host-b-webapp/login_app.py`

```python
1. Extract credentials from form
2. Validate input (not empty)
3. Create analysis request:
   {
     "input": "username: admin' OR '1'='1, password: test123",
     "ip_address": "127.0.0.1"
   }
4. Send to Threat Detector API
   POST http://localhost:8081/analyze
5. Wait for response (timeout: 30s)
```

### **Step 3: Threat Detector Analysis**
**File:** `host-c-detection/threat_detector.py`

```python
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ THREAT DETECTOR PROCESSING                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚ 1. Input Normalization                                  â”‚
â”‚    â”œâ”€ URL decode: unquote(input_text)                   â”‚
â”‚    â”œâ”€ Replace '+' with spaces                           â”‚
â”‚    â””â”€ Normalize whitespace                              â”‚
â”‚                                                          â”‚
â”‚ 2. Whitelist Check (LOCAL - FAST)                       â”‚
â”‚    â”œâ”€ Check against legitimate patterns:                â”‚
â”‚    â”‚   â€¢ AAA/Aston1, BBB/Aston2, etc.                   â”‚
â”‚    â”œâ”€ If MATCH:                                         â”‚
â”‚    â”‚   â”œâ”€ threat_detected: False                        â”‚
â”‚    â”‚   â”œâ”€ threat_type: "BENIGN_LOGIN"                   â”‚
â”‚    â”‚   â”œâ”€ detection_method: "whitelist"                 â”‚
â”‚    â”‚   â”œâ”€ api_called: False                             â”‚
â”‚    â”‚   â””â”€ processing_time: ~0.002s                      â”‚
â”‚    â””â”€ BYPASS LLM âœ“                                      â”‚
â”‚                                                          â”‚
â”‚ 3. LLM Analysis (AWS REMOTE - SLOWER)                   â”‚
â”‚    If NOT in whitelist:                                 â”‚
â”‚    â”œâ”€ Create Ollama client:                             â”‚
â”‚    â”‚   client = ollama.Client(                          â”‚
â”‚    â”‚       host='http://98.92.213.6:11434'              â”‚
â”‚    â”‚   )                                                 â”‚
â”‚    â”‚                                                     â”‚
â”‚    â”œâ”€ Prepare security prompt:                          â”‚
â”‚    â”‚   """                                               â”‚
â”‚    â”‚   You are a cybersecurity expert analyzing         â”‚
â”‚    â”‚   login inputs for security threats.               â”‚
â”‚    â”‚                                                     â”‚
â”‚    â”‚   Input: "username: admin' OR '1'='1, ..."         â”‚
â”‚    â”‚                                                     â”‚
â”‚    â”‚   Response format (JSON only):                     â”‚
â”‚    â”‚   {"decision": "THREAT"} OR {"decision": "SAFE"}   â”‚
â”‚    â”‚   """                                               â”‚
â”‚    â”‚                                                     â”‚
â”‚    â”œâ”€ Send to AWS EC2:                                  â”‚
â”‚    â”‚   response = client.generate(                      â”‚
â”‚    â”‚       model='codellama:13b',                       â”‚
â”‚    â”‚       prompt=prompt,                               â”‚
â”‚    â”‚       options={"temperature": 0.0}                 â”‚
â”‚    â”‚   )                                                 â”‚
â”‚    â”‚                                                     â”‚
â”‚    â””â”€ Parse LLM response:                               â”‚
â”‚        â”œâ”€ Extract JSON decision                         â”‚
â”‚        â”œâ”€ If "THREAT":                                  â”‚
â”‚        â”‚   â”œâ”€ threat_detected: True                     â”‚
â”‚        â”‚   â””â”€ threat_type: "LLM_DETECTED_THREAT"        â”‚
â”‚        â”œâ”€ If "SAFE":                                    â”‚
â”‚        â”‚   â”œâ”€ threat_detected: False                    â”‚
â”‚        â”‚   â””â”€ threat_type: "LLM_ANALYSIS_SAFE"          â”‚
â”‚        â””â”€ processing_time: ~40-50s (network latency)    â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Step 4: AWS LLM Processing**
**Location:** AWS EC2 (t4g.xlarge, Ubuntu 24.04, ARM64)  
**IP:** 98.92.213.6:11434

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AWS EC2 INSTANCE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚ Ollama Server (systemd service)                 â”‚
â”‚ â”œâ”€ Model: codellama:13b                         â”‚
â”‚ â”œâ”€ Size: 7.4 GB on disk                         â”‚
â”‚ â”œâ”€ RAM Usage: ~8-10 GB when loaded              â”‚
â”‚ â”œâ”€ Quantization: Q4_0 (4-bit)                   â”‚
â”‚ â””â”€ Parameter Count: 13 Billion                  â”‚
â”‚                                                  â”‚
â”‚ Processing:                                     â”‚
â”‚ 1. Receive HTTP POST request                    â”‚
â”‚ 2. Load model into memory (if not loaded)       â”‚
â”‚ 3. Tokenize input prompt                        â”‚
â”‚ 4. Run inference on CodeLlama 13B               â”‚
â”‚ 5. Generate JSON response:                      â”‚
â”‚    {                                            â”‚
â”‚      "decision": "THREAT",                      â”‚
â”‚      "reason": "SQL injection detected..."      â”‚
â”‚    }                                            â”‚
â”‚ 6. Return response to MacBook                   â”‚
â”‚                                                  â”‚
â”‚ Typical Processing Time: 30-50 seconds          â”‚
â”‚ (Includes network latency + inference)          â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Step 5: Response to Web Application**
```json
{
  "threat_detected": true,
  "threat_type": "LLM_DETECTED_THREAT",
  "detection_method": "llm_analysis",
  "processing_time": 44.218,
  "model_version": "advanced-security-v1.0",
  "pattern_matched": "none",
  "api_called": true,
  "ai_response": "{\"decision\": \"THREAT\", \"reason\": \"SQL injection attempt\"}",
  "timestamp": "2025-10-22T02:09:38.525722",
  "detection_latency": 44.219
}
```

### **Step 6: Web Application Response**
```python
# In login_app.py
if threat_detected:
    # Still allow login (fail-open for monitoring)
    login_blocked = False
    logger.warning(f"Threat detected but login allowed")

# Store in database
store_session_record(attempt_data)

# Always show success page
return render_template('success.html', username=username)
```

### **Step 7: Dashboard Display**
**URL:** http://localhost:3000/monitor

Real-time display shows:
- âœ… Timestamp
- ğŸŒ IP Address
- ğŸ‘¤ Username
- ğŸ¤– Detection Engine: "AI (PHI)" or "Whitelist"
- ğŸ¯ LLM Analysis Status
- âš ï¸ Threat Type
- â±ï¸ Processing Time
- ğŸ“ Raw LLM Response

---

## ğŸ”§ Current Configuration

### **MacBook (Local)**
```yaml
Host: localhost
Services:
  - Web Application:
      Port: 3000
      File: host-b-webapp/login_app.py
      Python: /Users/mdshoyaibhossain/Desktop/Hybrid/.venv/bin/python
      
  - Threat Detector:
      Port: 8081
      File: host-c-detection/threat_detector.py
      Python: /Users/mdshoyaibhossain/Desktop/Hybrid/.venv/bin/python
      Environment:
        OLLAMA_HOST: "http://98.92.213.6:11434"
        OLLAMA_MODEL: "codellama:13b"
```

### **AWS EC2 Instance**
```yaml
Instance Details:
  ID: i-0787d08dd870595c4
  Type: t4g.xlarge (ARM64)
  vCPUs: 4
  RAM: 16 GB
  Storage: 50 GB (was 30 GB, increased)
  OS: Ubuntu Server 24.04 LTS
  
Network:
  Public IP: 98.92.213.6
  Security Groups:
    - Port 22 (SSH): 0.0.0.0/0
    - Port 11434 (Ollama): 0.0.0.0/0
    
Ollama Configuration:
  Service: systemd (always running)
  Host: 0.0.0.0:11434
  Config: /etc/systemd/system/ollama.service.d/override.conf
  Environment: OLLAMA_HOST=0.0.0.0:11434
  
Models Installed:
  - codellama:13b (ACTIVE - 7.4 GB)
  - codellama:34b (TOO LARGE - needs 19.3 GB RAM)
```

---

## ğŸ“ˆ Performance Metrics

### **Legitimate Login (Whitelist)**
- Detection Method: Local whitelist check
- Processing Time: ~0.002 seconds (2 milliseconds)
- API Called: No (bypasses LLM)
- Network: No external calls

### **Threat Detection (LLM)**
- Detection Method: AWS CodeLlama 13B
- Processing Time: ~40-50 seconds
- API Called: Yes
- Network: MacBook â†’ AWS EC2 (HTTP)
- Breakdown:
  - Network latency: ~5-10s
  - LLM inference: ~30-40s
  - Response processing: ~0.1s

---

## ğŸ”’ Security Features

### **Whitelist Patterns (Fast Path)**
```python
legitimate_patterns = [
    ('AAA', 'Aston1'),  ('BBB', 'Aston2'),  ('CCC', 'Aston3'),
    ('DDD', 'Aston4'),  ('EEE', 'Aston5'),  ('ZZZ', 'Aston6'),
    ('GGG', 'Aston7'),  ('HHH', 'Aston8'),  ('III', 'Aston10'),
    ('JJJ', 'Aston11'), ('KKK', 'Aston22'), ('LLL', 'Aston33'),
    ('MMM', 'Aston44'), ('PPP', 'Aston55'), ('QQQ', 'Aston77')
]
```

### **Threat Detection Capabilities**
AWS CodeLlama 13B can detect:
- âœ… SQL Injection (`' OR 1=1`, `admin'--`, etc.)
- âœ… Command Injection (`; rm -rf /`, `| cat /etc/passwd`)
- âœ… XSS Attempts (`<script>alert(1)</script>`)
- âœ… Path Traversal (`../../etc/passwd`)
- âœ… LDAP Injection
- âœ… NoSQL Injection
- âœ… Unusual patterns and anomalies

---

## ğŸ’° Cost Analysis

### **AWS EC2 Costs**
```
Instance: t4g.xlarge
Hourly Rate: $0.1344 USD/hour

Monthly Costs:
- Running 24/7:  ~$97/month  (compute) + $5/month  (50GB storage) = $102/month
- Running 8h/day: ~$32/month  (compute) + $5/month  (storage)    = $37/month
- Stopped:        $0/month    (compute) + $5/month  (storage)    = $5/month

Recommendation: Stop when not in use to save ~90% on costs
```

---

## ğŸš€ Starting the System

### **Method 1: Start Services Individually**
```bash
# Terminal 1: Start Threat Detector
cd ~/Desktop/Hybrid/host-c-detection
~/.../Hybrid/.venv/bin/python threat_detector.py

# Terminal 2: Start Web Application  
cd ~/Desktop/Hybrid/host-b-webapp
~/.../Hybrid/.venv/bin/python login_app.py

# Access:
# - Web App: http://localhost:3000
# - Monitor: http://localhost:3000/monitor
# - API: http://localhost:8081/analyze
```

### **Method 2: Background Processes**
```bash
cd ~/Desktop/Hybrid

# Start both in background
.venv/bin/python start_all.py &

# Check status
lsof -i:3000,8081

# View logs
tail -f /tmp/hybrid.log
```

---

## ğŸ§ª Testing Examples

### **Test 1: Legitimate Login (Whitelist)**
```bash
curl -X POST http://localhost:3000/login \
  -d "username=AAA&password=Aston1"

Expected:
- Processing: ~2ms
- Detection: Whitelist (no LLM call)
- Result: Success page
```

### **Test 2: SQL Injection (LLM Detection)**
```bash
curl -X POST http://localhost:3000/login \
  -d "username=admin' OR '1'='1&password=test"

Expected:
- Processing: ~40-50s
- Detection: AWS CodeLlama 13B
- Result: Threat detected + Success page (fail-open)
- Dashboard: Shows "LLM_DETECTED_THREAT"
```

### **Test 3: Direct API Call**
```bash
curl -X POST http://localhost:8081/analyze \
  -H "Content-Type: application/json" \
  -d '{"input":"test attack","ip_address":"127.0.0.1"}'

Expected JSON Response:
{
  "threat_detected": true/false,
  "threat_type": "LLM_DETECTED_THREAT" or "LLM_ANALYSIS_SAFE",
  "detection_method": "llm_analysis",
  "processing_time": 44.218,
  "ai_response": "{\"decision\": \"THREAT\", ...}"
}
```

---

## ğŸ—„ï¸ Data Storage

### **Threat Detector Database**
```
Location: host-c-detection/data/regex_analytics.db
Table: hybrid_detections
Stores:
- Input data
- Threat detection results
- Processing times
- IP addresses
- LLM responses
```

### **Web Application Database**
```
Location: host-b-webapp/data/web_sessions.db
Table: login_sessions
Stores:
- Username/password attempts
- Timestamps
- Threat analysis results
- Login blocked status
```

---

## ğŸ”„ Stop/Manage AWS Instance

### **Stop Instance (Save Money)**
```bash
# From AWS Console:
EC2 â†’ Instances â†’ Select i-0787d08dd870595c4 â†’ Instance State â†’ Stop

# From Terminal:
aws ec2 stop-instances --instance-ids i-0787d08dd870595c4

# Note: Public IP will change when restarted
# Update threat_detector.py with new IP
```

### **Restart Instance**
```bash
aws ec2 start-instances --instance-ids i-0787d08dd870595c4

# Get new IP:
aws ec2 describe-instances --instance-ids i-0787d08dd870595c4 \
  --query 'Reservations[0].Instances[0].PublicIpAddress'
```

---

## ğŸ“ Key Differences from Previous Setup

### **Before (Local)**
- LLM: Local Ollama on MacBook
- Model: llama3.1:8b (wouldn't work with 8GB RAM)
- Processing: All local
- Cost: $0

### **After (AWS Cloud)**
- LLM: Remote Ollama on AWS EC2
- Model: CodeLlama 13B (specifically for code/security)
- Processing: MacBook sends HTTP requests to AWS
- Cost: ~$0.13/hour when running
- Benefit: Can use larger, more capable models

---

## ğŸ¯ System Status Commands

```bash
# Check if services are running
lsof -i:3000,8081

# Test AWS LLM connection
curl http://98.92.213.6:11434/api/tags

# Test threat detector
curl http://localhost:8081/health

# Test web app
curl http://localhost:3000/health

# View real-time logs
tail -f host-c-detection/data/*.log
tail -f host-b-webapp/data/*.log

# Kill all services
lsof -ti:3000,8081 | xargs kill -9
```

---

## âœ… Verification Checklist

- [x] AWS EC2 instance running (i-0787d08dd870595c4)
- [x] Ollama service running on AWS (0.0.0.0:11434)
- [x] CodeLlama 13B model installed on AWS
- [x] Security groups allow port 11434
- [x] Threat detector using AWS LLM (98.92.213.6:11434)
- [x] Web application running (localhost:3000)
- [x] Threat detector running (localhost:8081)
- [x] Dashboard accessible (localhost:3000/monitor)
- [x] LLM successfully detecting threats
- [x] Processing time: ~40-50s for LLM analysis
- [x] Whitelist bypass working (~2ms)

---

**System is fully operational with AWS cloud LLM! ğŸ‰**
